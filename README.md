# BERT_DIS_NER

BERT + CRF를 이용한 개체명 인식 모델.

**BERT**와 **CRF**를 이용해서 **음절단위**로 학습시켰으며  질병 명을 인식하는 것을 목표로 만듬. BERT 토크나이저의 경우 [KoCharELECTRA](https://github.com/monologg/KoCharELECTRA)의 음절 VOCAB을 이용하여 만듬.



# 시스템 개요

먼저, 질병명 인식 모델을 만들게 된 이유는 반려동물 예진 시스템을 만들기 위해서 만들어짐. 

 사용자가 반려동물의 이상 행동에 대한 상태(문장)를 입력하면 입력받은 상태와 유사한 사례의 답변을 통해 반려동물의 상태를 간단하게 예진 가능하게 하는 것을 목표로 하는 시스템. 

BERT_DIS_NER은 사용자가 입력한 문장과 유사한 사례 중 질병이 포함된 문장을 찾아서 인터페이스에 띄우는 것이 목표.



# 데이터 수집

- 데이터 출처: 네이버 지식 iN 전문의 답변 Q&A

  |      |  사람   |  동물  |
  | :--: | :-----: | :----: |
  | 학습 | 303,220 | 15,731 |
  | 검증 | 102,367 | 2,756  |
  
# 질병명 사전 구축
질병명 사전의 경우 사람 질병명은 질병 백과사전을 이용함. 동물 질병명의 경우 공공 데이터 셋을 이용함.

사람 질병명은 총 **3,704**개, 동물질병명은 총 **1,538**개를 수집. 

문장에 태깅된 질병명의 경우 사람 질병명은 **1,310**개, 동물 질병명은 **649**개를 태깅. 구축된 질병명 사전을 이용하여 문장에서의 질병을 태깅한 후 모델 학습에 사용됨. 동물 질병명의 경우 학습되지 않은 질병명도 찾아내는 것이 목표이기에 649개 중 240개의 질병명은 검증셋에만 포함되도록 나눔

# 학습

BERT_DIS_NER은 동물 질병명 인식을 위해 만들기 시작했지만, 데이터 수가 부족 약 1만 8천 문장으로 부족. 부족한 데이터의 해결방안으로 **사람 질병 문장**을 이용.

동물과 사람의 질병명이 유사한 것을 이용.

1. 사람 질병 문장을 이용하여 모델 학습
2. 이후 동물 질병 문장을 이용해서 추가 학습

사람 질병의 경우, 학습 셋을 1Epoch 학습 시킴.

동물 질병을 이용하여 사랍 질병을 학습시킨 모델을 파인튜닝할 경우 동물 질병 학습 셋을 4Epoch 학습 시킴.



# 정확도

**Seqeval**의 F1_Score 적용.

|          | 사람 질병 | 동물 질병 | 사람 + 동물 질병 | 
| -------- | ----------- | ----------- | ----------- |
| F1_Score | 0.71       | 0.74        | 0.77        |

사람 질병명만을 학습시켰을 때 0.71, 동물 질병명만을 학습했을 때 0.74, 사람 + 동물 질병명을 이용했을 때 0.77의 결과를 보임. 사람 질병명 만을 이용했을 때도 나쁘지 않은 결과를 보였으며, 사람 + 동물 질병명을 학습시켰을 때가 큰 폭은 아니지만 더 좋은 결과를 보임.

# 후기
개체명 인식 프로젝트를 진행하며, 버트에 대해 공부할 수 있었으며, 개체명 인식의 경우 음절단위로 학습해도 괜찮은 결과를 보인다는 것을 알 수 있었다. 사람질병명과 동물질병명의 단어 형태의 유사성이나 문장의 위치에서의 유사성 등을 이용한 성능 향상을 목표로 했으며 실제로 미미하지만, 향상된 결과를 보였다는 것에 의미가 있었던 것 같다. 

# 모델

- [DIS_NER](https://drive.google.com/file/d/1Uoyh24dLUF9UpsD2fNoZPYFkldw8rYVf/view?usp=sharing)

# Reference Repo

1. [KoBERT](https://github.com/SKTBrain/KoBERT)
2. [KoBERT_CRF_NER](https://github.com/eagle705/pytorch-bert-crf-ner#reference-repo)
3. [KoCharELECTRA](https://github.com/monologg/KoCharELECTRA)
